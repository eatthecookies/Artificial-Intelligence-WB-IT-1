{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n"
     ]
    }
   ],
   "source": [
    "# (1)\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits, load_boston\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9636765235959711, 0.9636765235959711)\n"
     ]
    }
   ],
   "source": [
    "# (2)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return tanh(total)\n",
    "\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9636765235959711, 0.9636765235959711)\n"
     ]
    }
   ],
   "source": [
    "# tanh\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return tanh(total)\n",
    "\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8757270529783324, 0.8757270529783324)\n"
     ]
    }
   ],
   "source": [
    "# sigmoid\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "# relu\n",
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return relu(total)\n",
    "    \n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes :  (1797, 64) (1797,)\n",
      "Dataset Sizes :  (506, 13) (506,)\n",
      "**********MLPClassifier**********\n",
      "\n",
      "Dataset Sizes :  (150,) (150,)\n",
      "Train/Test Sizes :  (1437, 64) (360, 64) (1437,) (360,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sasha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 9 9 6 1 6 6 9 8 7 4 2 1 4 3]\n",
      "[5 9 9 6 1 6 6 9 8 7 4 2 1 4 3]\n",
      "Test Accuracy : 0.983\n",
      "Training Accuracy : 1.000\n",
      "Loss :  0.0034728684994180608\n",
      "Number of Coefs :  2\n",
      "Number of Intercepts :  2\n",
      "Number of Iterations for Which Estimator Ran :  125\n",
      "Name of Output Layer Activation Function :  softmax\n",
      "\n",
      "**********MLPRegressor**********\n",
      "\n",
      "Dataset Sizes :  (30,) (30,)\n",
      "Train/Test Sizes :  (404, 13) (102, 13) (404,) (102,)\n",
      "[ 7.32543601 24.33417853 32.46700507 15.19086054 25.6749167  25.07797685\n",
      " 27.20985668  2.62269853 15.25691994 28.02637784]\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2]\n",
      "Test R^2 Score : 0.462\n",
      "Training R^2 Score : 0.510\n",
      "Loss :  28.538174061119626\n",
      "Number of Coefs :  2\n",
      "Number of Iterations for Which Estimator Ran :  130\n",
      "Name of Output Layer Activation Function :  identity\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_digits, load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "digits = load_digits()\n",
    "x_digits, y_digits = digits.data, digits.target\n",
    "print('Dataset Sizes : ', x_digits.shape, y_digits.shape)\n",
    "\n",
    "boston = load_boston()\n",
    "x_boston, y_boston = boston.data, boston.target\n",
    "print('Dataset Sizes : ', x_boston.shape, y_boston.shape)\n",
    "\n",
    "urls = {\n",
    "    'class': r'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv',\n",
    "    'reg': r'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n",
    "}\n",
    "\n",
    "print('**********MLPClassifier**********\\n')\n",
    "class_data = pd.read_csv(urls['class'])\n",
    "x_data, y_data = class_data['sepal.length'], class_data['sepal.width']\n",
    "print('Dataset Sizes : ', x_data.shape, y_data.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_digits, y_digits, train_size=.80, test_size=.20, stratify=y_digits, random_state=123)\n",
    "print('Train/Test Sizes : ', x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_classifier = MLPClassifier(random_state=123)\n",
    "mlp_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_preds = mlp_classifier.predict(x_test)\n",
    "\n",
    "print(y_preds[:15])\n",
    "print(y_test[:15])\n",
    "# Метод Score для оценки точности моделей классификации\n",
    "print('Test Accuracy : %.3f'%mlp_classifier.score(x_test, y_test))\n",
    "\n",
    "print('Training Accuracy : %.3f'%mlp_classifier.score(x_train, y_train))\n",
    "\n",
    "print('Loss : ', mlp_classifier.loss_)\n",
    "print('Number of Coefs : ', len(mlp_classifier.coefs_))\n",
    "print('Number of Intercepts : ', len(mlp_classifier.intercepts_))\n",
    "print('Number of Iterations for Which Estimator Ran : ', mlp_classifier.n_iter_)\n",
    "print('Name of Output Layer Activation Function : ', mlp_classifier.out_activation_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n**********MLPRegressor**********\\n')\n",
    "\n",
    "reg_data = pd.read_csv(urls['reg'])\n",
    "x_data, y_data = reg_data['YearsExperience'], reg_data['Salary']\n",
    "print('Dataset Sizes : ', x_data.shape, y_data.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_boston, y_boston, train_size=.80, test_size=.20, random_state=123)\n",
    "print('Train/Test Sizes : ', x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor = MLPRegressor(random_state=123)\n",
    "mlp_regressor.fit(x_train, y_train)\n",
    "\n",
    "y_preds = mlp_regressor.predict(x_test)\n",
    "\n",
    "print(y_preds[:10])\n",
    "print(y_test[:10])\n",
    "# Метод Score оценивает точность моделей классификации\n",
    "print('Test R^2 Score : %.3f'%mlp_regressor.score(x_test, y_test))\n",
    "print('Training R^2 Score : %.3f'%mlp_regressor.score(x_train, y_train))\n",
    "\n",
    "print('Loss : ', mlp_regressor.loss_)\n",
    "print('Number of Coefs : ', len(mlp_regressor.coefs_))\n",
    "[weights.shape for weights in mlp_regressor.coefs_]\n",
    "print('Number of Iterations for Which Estimator Ran : ', mlp_regressor.n_iter_)\n",
    "print('Name of Output Layer Activation Function : ', mlp_regressor.out_activation_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
